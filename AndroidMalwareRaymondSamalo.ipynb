{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b6e586b",
   "metadata": {},
   "source": [
    "# Android Malware\n",
    "\n",
    "Our dataset for this project is taken from https://www.mlsec.org/docs/2014-ndss.pdf which is a known dataset of android malware data.\n",
    "This is a public dataset which we downloaded from https://figshare.com/articles/dataset/Android_malware_dataset_for_machine_learning_2/5854653/1\n",
    "\n",
    "There are other similar datasets for android malware for example:\n",
    "- https://github.com/DefenseDroid/DefenseDroid    \n",
    "- https://www.unb.ca/cic/datasets/maldroid-2020.html \n",
    "    - file: feature_vectors_syscalls_frequency_5_Cat.csv \n",
    "    - This is a very comprehensive and clean data set. The problem with this dataset is that it is too clean to demonstrate preprocessing steps in our project.\n",
    "- https://www.unb.ca/cic/datasets/andmal2020.html\n",
    "    - This data set similar to the other Maldroid 2020 data set. However, in contrast it contains multiple csv files and we need to spend considerable effort\n",
    "      to create a data set that can be used for our assignment.\n",
    "Hence, the  Drebin dataset is originally chosen as made it easier to work with for our purpose and demonstrate the ML processes.\n",
    "However, after running exploratory data analysis, we discovered that Drebin dataset is flawed given it contains a lot of duplicates \n",
    "and we found a paper that highlighted the same issue https://ieeexplore.ieee.org/document/9609892\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a411bc0",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cc912a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa0709",
   "metadata": {},
   "source": [
    "# Drebin DataSet Exploratory Data Analysis\n",
    "\n",
    "Let's do basic analysis of our dataset and hopefully we gain some insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7a99031f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show size\n",
      "(15036, 216)\n",
      "show features\n",
      "           transact  onServiceConnected   bindService  attachInterface  \\\n",
      "count  15036.000000        15036.000000  15036.000000     15036.000000   \n",
      "mean       0.426443            0.446595      0.442671         0.413208   \n",
      "std        0.494576            0.497156      0.496719         0.492426   \n",
      "min        0.000000            0.000000      0.000000         0.000000   \n",
      "25%        0.000000            0.000000      0.000000         0.000000   \n",
      "50%        0.000000            0.000000      0.000000         0.000000   \n",
      "75%        1.000000            1.000000      1.000000         1.000000   \n",
      "max        1.000000            1.000000      1.000000         1.000000   \n",
      "\n",
      "       ServiceConnection  android.os.Binder      SEND_SMS  \\\n",
      "count       15036.000000       15036.000000  15036.000000   \n",
      "mean            0.444932           0.486898      0.236632   \n",
      "std             0.496975           0.499845      0.425029   \n",
      "min             0.000000           0.000000      0.000000   \n",
      "25%             0.000000           0.000000      0.000000   \n",
      "50%             0.000000           0.000000      0.000000   \n",
      "75%             1.000000           1.000000      0.000000   \n",
      "max             1.000000           1.000000      1.000000   \n",
      "\n",
      "       Ljava.lang.Class.getCanonicalName  Ljava.lang.Class.getMethods  \\\n",
      "count                       15036.000000                 15036.000000   \n",
      "mean                            0.330806                     0.282389   \n",
      "std                             0.470519                     0.450177   \n",
      "min                             0.000000                     0.000000   \n",
      "25%                             0.000000                     0.000000   \n",
      "50%                             0.000000                     0.000000   \n",
      "75%                             1.000000                     1.000000   \n",
      "max                             1.000000                     1.000000   \n",
      "\n",
      "       Ljava.lang.Class.cast  ...  SET_ORIENTATION  READ_CONTACTS  \\\n",
      "count           15036.000000  ...     15036.000000   15036.000000   \n",
      "mean                0.312583  ...         0.007050       0.233307   \n",
      "std                 0.463561  ...         0.083669       0.422950   \n",
      "min                 0.000000  ...         0.000000       0.000000   \n",
      "25%                 0.000000  ...         0.000000       0.000000   \n",
      "50%                 0.000000  ...         0.000000       0.000000   \n",
      "75%                 1.000000  ...         0.000000       0.000000   \n",
      "max                 1.000000  ...         1.000000       1.000000   \n",
      "\n",
      "       DEVICE_POWER  HARDWARE_TEST  ACCESS_WIFI_STATE  WRITE_EXTERNAL_STORAGE  \\\n",
      "count  15036.000000   15036.000000       15036.000000            15036.000000   \n",
      "mean       0.017425       0.004256           0.434424                0.666135   \n",
      "std        0.130852       0.065105           0.495698                0.471608   \n",
      "min        0.000000       0.000000           0.000000                0.000000   \n",
      "25%        0.000000       0.000000           0.000000                0.000000   \n",
      "50%        0.000000       0.000000           0.000000                1.000000   \n",
      "75%        0.000000       0.000000           1.000000                1.000000   \n",
      "max        1.000000       1.000000           1.000000                1.000000   \n",
      "\n",
      "       ACCESS_FINE_LOCATION  SET_WALLPAPER_HINTS  SET_PREFERRED_APPLICATIONS  \\\n",
      "count          15036.000000         15036.000000                15036.000000   \n",
      "mean               0.290835             0.016028                    0.007050   \n",
      "std                0.454163             0.125588                    0.083669   \n",
      "min                0.000000             0.000000                    0.000000   \n",
      "25%                0.000000             0.000000                    0.000000   \n",
      "50%                0.000000             0.000000                    0.000000   \n",
      "75%                1.000000             0.000000                    0.000000   \n",
      "max                1.000000             1.000000                    1.000000   \n",
      "\n",
      "       WRITE_SECURE_SETTINGS  \n",
      "count           15036.000000  \n",
      "mean                0.044959  \n",
      "std                 0.207220  \n",
      "min                 0.000000  \n",
      "25%                 0.000000  \n",
      "50%                 0.000000  \n",
      "75%                 0.000000  \n",
      "max                 1.000000  \n",
      "\n",
      "[8 rows x 214 columns]\n",
      "show headers\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15036 entries, 0 to 15035\n",
      "Columns: 216 entries, transact to class\n",
      "dtypes: int64(214), object(2)\n",
      "memory usage: 24.8+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pq/ctzkfdzj3cg4894zy28yqknc0000gn/T/ipykernel_41995/4086481383.py:2: DtypeWarning: Columns (92) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(url) # read our data frame\n"
     ]
    }
   ],
   "source": [
    "url=\"https://raw.githubusercontent.com/raymondsamalo/25S1-C-NYP-ITI111-Applied-Machine-Learning/refs/heads/main/drebin-215-dataset-5560malware-9476-benign.csv\"\n",
    "df=pd.read_csv(url) # read our data frame\n",
    "print(\"show size\")\n",
    "print(df.shape)\n",
    "print(\"show features\")\n",
    "print(df.describe())\n",
    "print(\"show headers\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34effdfd",
   "metadata": {},
   "source": [
    "From basic analysis we found that our data contains mostly 0 or 1 which represent whether the Application uses the android features/function call or not.\n",
    "```\n",
    "Columns: 216 entries, transact to class\n",
    "dtypes: int64(214), object(2)\n",
    "\n",
    "```\n",
    "\n",
    "We have 216 columns and 2 of the columns are object while the rest are int64 / numeric.\n",
    "\n",
    "We have quite a number of columns or features. Hence we need to simplify by filtering columns that does not have strong correlation to our label.\n",
    "\n",
    "Pandas reported issue for columns 92\n",
    "``` DtypeWarning: Columns (92) have mixed types. Specify dtype option on import or set low_memory=False.```.\n",
    "\n",
    "Let's take a deeper look on this column 92.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd13aa2",
   "metadata": {},
   "source": [
    "# Preprocessing Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0698af83",
   "metadata": {},
   "source": [
    "## Clean Up Column 92 and Object Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "00c39cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TelephonyManager.getSimCountryIso\n",
      "['0' '1' '?' 1 0]\n"
     ]
    }
   ],
   "source": [
    "column_names_index = df.columns\n",
    "print(column_names_index[92]) # output TelephonyManager.getSimCountryIso\n",
    "print(df['TelephonyManager.getSimCountryIso'].unique()) # output array(['0', '1', '?', 1, 0], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bd5276",
   "metadata": {},
   "source": [
    "We discovered that the column 92 or `TelephonyManager.getSimCountryIso` contains `['0' '1' '?' 1 0]`.\n",
    "\n",
    "We need to handle unknown '?' data and also convert '0','1' to integer.\n",
    "\n",
    "However, the df.info() shows us that we have two object columns. \n",
    "Let's check out the other object column to gain deeper insight to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0490dd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object columns: ['TelephonyManager.getSimCountryIso', 'class']\n",
      "Column                                  Values\n",
      "TelephonyManager.getSimCountryIso       ['0' '1' '?' 1 0]\n",
      "class                                   ['S' 'B']\n"
     ]
    }
   ],
   "source": [
    "object_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Object columns: {object_columns}\") # Object columns: ['TelephonyManager.getSimCountryIso', 'class']\n",
    "print(f\"{'Column':40}Values\")\n",
    "for i in object_columns:\n",
    "    print(f\"{i:40}{df[i].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ac8046",
   "metadata": {},
   "source": [
    "We discover that beside 'TelephonyManager.getSimCountryIso', the other object or string column is 'class'.\n",
    "For 'class' column, the values are ['S' 'B']. \n",
    "We do not need to handle missing value for 'class' column but we do need to convert 'S' to suspicious malware and 'B' to benign.\n",
    "We shall do this by converting the value to integer 1 for Malware and 0 for benign in a new column.\n",
    "\n",
    "Alright, given we know the two columns that we need to handle, let's preprocess them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c4106a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check values of TelephonyManager.getSimCountryIso\n",
      "before ['0' '1' '?' 1 0] -> after [ 0.  1. nan]\n",
      "Check column values\n",
      "is all values are in [0,1, NaN]? True\n"
     ]
    }
   ],
   "source": [
    "get_sim_country_column='TelephonyManager.getSimCountryIso'\n",
    "df['malware']=(df['class']=='S').astype(int)\n",
    "df.drop('class',axis=1,inplace=True)\n",
    "before_values=df[get_sim_country_column].unique()\n",
    "df[get_sim_country_column] = pd.to_numeric(df[get_sim_country_column], errors='coerce') \n",
    "after_values=df[get_sim_country_column].unique()\n",
    "\n",
    "print(f\"Check values of {get_sim_country_column}\")\n",
    "print(f\"before {before_values} -> after {after_values}\")\n",
    "\n",
    "print(\"Check column values\")\n",
    "all_zeros_or_ones_nan = df.isin([0, 1, np.nan]).all().all()\n",
    "print(f\"is all values are in [0,1, NaN]? {all_zeros_or_ones_nan}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdc46e7",
   "metadata": {},
   "source": [
    "It seemed our data is simply 0 or 1 or NaN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e3f24",
   "metadata": {},
   "source": [
    "## Check For Duplicates Data\n",
    "\n",
    "First let's check duplicates data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "16a1d36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows count: 15036\n",
      "Duplicated rows count: 7775\n",
      "Duplicated rows percentage: 51.70923117850492\n"
     ]
    }
   ],
   "source": [
    "\n",
    "duplicated_row_count = df.duplicated().sum()\n",
    "total_row_count = df.shape[0]\n",
    "duplicated_row_percentage = (duplicated_row_count/total_row_count*100)\n",
    "print(f\"Total rows count: {total_row_count}\")\n",
    "print(f\"Duplicated rows count: {duplicated_row_count}\")\n",
    "print(f\"Duplicated rows percentage: {duplicated_row_percentage}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59da852",
   "metadata": {},
   "source": [
    "During this analysis we are surprised that Debrin data has quite a number of duplicates: \n",
    "```\n",
    "Total rows count: 15036\n",
    "Duplicated rows count: 7775\n",
    "Duplicated rows percentage: 51.70923117850492\n",
    "```\n",
    "More than half of rows in Debrin is a duplicate, we searched internet and discover a paper that mention the same problem https://ieeexplore.ieee.org/document/9609892\n",
    "\n",
    "We decided to continue with Debrin dataset with the duplicates removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "641cfc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Duplicated rows:\n",
      " 7261\n",
      "Check whether we have sufficient malware vs non malware data\n",
      "malware\n",
      "0    5540\n",
      "1    1721\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_no_duplicates = df.drop_duplicates()\n",
    "print(\"Non Duplicated rows:\\n\",df_no_duplicates.shape[0])\n",
    "print(\"Check whether we have sufficient malware vs non malware data\")\n",
    "print(df_no_duplicates[\"malware\"].value_counts())\n",
    "\n",
    "df = df_no_duplicates # replace our data frame with non-duplicated rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0847992",
   "metadata": {},
   "source": [
    "After removing the duplicate rows, our data set is still reasonably sufficient for our need with \n",
    "- benign sample    5540\n",
    "- malware sample    1721\n",
    "Roughly 23 % data shows malware and 77 % benign. \n",
    "\n",
    "Let's deal with missing data next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8b5fe6",
   "metadata": {},
   "source": [
    "## Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ef6c1a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List all column with missing data\n",
      "['TelephonyManager.getSimCountryIso']\n",
      "List all rows with missing data\n",
      "Index([176, 2109], dtype='int64')\n",
      "Missing data is 2 out of 7261\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"List all column with missing data\")\n",
    "print(df.columns[df.isna().any()].tolist()) # return ['TelephonyManager.getSimCountryIso'] as the only columen with nan value\n",
    "rows_with_nan = df[df.isnull().any(axis=1)].index\n",
    "no_of_rows = df.shape[0]\n",
    "print(\"List all rows with missing data\")\n",
    "print(rows_with_nan)\n",
    "no_of_rows_missing_data=rows_with_nan.shape[0]\n",
    "print(f\"Missing data is {no_of_rows_missing_data} out of {no_of_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bad5eb",
   "metadata": {},
   "source": [
    "Given we only have 2 rows out of 7261 with missing data, let us simply remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a3e937e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of rows with missing data is now 0 out of 7259\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "rows_with_nan = df[df.isnull().any(axis=1)].index\n",
    "no_of_rows_missing_data=rows_with_nan.shape[0]\n",
    "no_of_rows = df.shape[0]\n",
    "print(f\"No of rows with missing data is now {no_of_rows_missing_data} out of {no_of_rows}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
